import logging
import json
import re
import time
import asyncio
from typing import (
    AsyncGenerator,
    Dict,
    Any,
    List,
    Union,
    Optional,
    Tuple,
)
import uuid
from datetime import datetime
from langchain_core.output_parsers import StrOutputParser
from fastapi import BackgroundTasks
from fastapi.responses import JSONResponse
from langchain_core.documents import Document
from sqlalchemy.ext.asyncio import AsyncSession
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import (
    HumanMessage,
    AIMessage,
    SystemMessage,
    ToolMessage,
    BaseMessage,
)
from langchain_core.runnables import Runnable

from pydantic import SecretStr

# anthropic ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ import ì¶”ê°€
import anthropic

from app.db import crud
from app.db.session import SessionLocal
from app.models.chat_models import (
    ChatRequest,
    CargoTrackingResponse,
    CargoTrackingError,
)
from app.services.chat_history_service import PostgresChatMessageHistory
from app.services.langchain_service import LLMService
from app.services.cargo_tracking_service import CargoTrackingService
from app.services.hscode_classification_service import HSCodeClassificationService
from app.services.intent_classification_service import (
    IntentClassificationService,
    IntentType,
)
from app.services.enhanced_detail_generator import EnhancedDetailGenerator
from app.core.config import settings
from app.core.llm_provider import llm_provider
from app.services.parallel_task_manager import ParallelTaskManager
from app.services.sse_event_generator import SSEEventGenerator
from app.models import db_models
from langchain_core.messages import AIMessageChunk

logger = logging.getLogger(__name__)


async def generate_session_title(user_message: str, ai_response: str) -> str:
    try:
        title_llm = ChatAnthropic(
            model_name="claude-3-5-haiku-20241022",
            api_key=SecretStr(settings.ANTHROPIC_API_KEY),
            temperature=0.3,
            max_tokens_to_sample=100,
            timeout=300.0,
            stop=None,
        )
        prompt = f"""ë‹¤ìŒ ëŒ€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§§ê³  ëª…í™•í•œ ì„¸ì…˜ ì œëª©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {user_message}
AI ì‘ë‹µ: {ai_response[:500]}...

ìš”êµ¬ì‚¬í•­:
1. í•œêµ­ì–´ë¡œ ì‘ì„±
2. ìµœëŒ€ 50ì ì´ë‚´
3. ëŒ€í™”ì˜ í•µì‹¬ ì£¼ì œë¥¼ í¬í•¨
4. ëª…ì‚¬í˜•ìœ¼ë¡œ ì¢…ê²°
5. íŠ¹ìˆ˜ë¬¸ìë‚˜ ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€

ì˜ˆì‹œ:
- "HSCode 8471.30 ê´€ë ¨ ê´€ì„¸ìœ¨ ë¬¸ì˜"
- "ë¯¸êµ­ ìˆ˜ì¶œ ê·œì œ í˜„í™© ì§ˆë¬¸"
- "ì¤‘êµ­ ë¬´ì—­ ì •ì±… ë³€í™” ë…¼ì˜"

ì œëª©ë§Œ ì‘ë‹µí•˜ì„¸ìš”:"""
        response = await title_llm.ainvoke([HumanMessage(content=prompt)])
        from app.utils.llm_response_parser import extract_text_from_anthropic_response

        title = extract_text_from_anthropic_response(response).strip()
        if not title:
            fallback_title = user_message[:30].strip()
            if len(user_message) > 30:
                fallback_title += "..."
            return fallback_title
        title = title.strip('"').strip("'")
        if len(title) > 50:
            title = title[:47] + "..."
        return title
    except Exception as e:
        logger.warning(f"ì„¸ì…˜ ì œëª© ìë™ ìƒì„± ì‹¤íŒ¨: {e}")
        fallback_title = user_message[:30].strip()
        if len(user_message) > 30:
            fallback_title += "..."
        return fallback_title


async def update_session_title(
    session_uuid_str: str,
    user_message: str,
    ai_response: str,
):
    """ì„¸ì…˜ ì œëª©ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ìƒì„±í•˜ê³  ì—…ë°ì´íŠ¸í•˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…"""
    async with SessionLocal() as db:
        try:
            title = await generate_session_title(user_message, ai_response)
            session_uuid = uuid.UUID(session_uuid_str)
            session = await db.get(db_models.ChatSession, session_uuid)
            if session:
                setattr(session, "session_title", title)
                await db.commit()
                logger.info(
                    f"ì„¸ì…˜(UUID: {session_uuid_str}) ì œëª© ì—…ë°ì´íŠ¸ ì™„ë£Œ: '{title}'"
                )
        except Exception as e:
            logger.error(
                f"ì„¸ì…˜(UUID: {session_uuid_str}) ì œëª© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True
            )
            await db.rollback()


async def _extract_hscode_from_message(
    message: str,
) -> tuple[Optional[str], Optional[str]]:
    """
    ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ HSCodeì™€ í’ˆëª©ëª…ì„ ì¶”ì¶œí•˜ëŠ” ê²½ëŸ‰í™”ëœ LLM í˜¸ì¶œ.
    ë©”ì¸ LLM í˜¸ì¶œ ì „ì— ì‹¤í–‰í•˜ì—¬ HSCodeë¥¼ í™•ì •í•¨.
    """
    try:
        extractor_llm = ChatAnthropic(
            model_name="claude-3-5-haiku-20241022",
            api_key=SecretStr(settings.ANTHROPIC_API_KEY),
            temperature=0.0,
            max_tokens_to_sample=200,
            timeout=300.0,
            stop=None,
        )
        prompt = f"""ì‚¬ìš©ìì˜ ë‹¤ìŒ ë©”ì‹œì§€ì—ì„œ HSCodeì™€ ê°€ì¥ í•µì‹¬ì ì¸ í’ˆëª©ëª…ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
- HSCodeëŠ” ìˆ«ìì™€ ì (.)ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤ (ì˜ˆ: 8471.30.0000).
- í’ˆëª©ëª…ì€ ì œí’ˆì„ ê°€ì¥ ì˜ ë‚˜íƒ€ë‚´ëŠ” ê°„ë‹¨í•œ ëª…ì‚¬ì…ë‹ˆë‹¤.
- ë‘˜ ì¤‘ í•˜ë‚˜ ë˜ëŠ” ë‘˜ ë‹¤ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

{{
  "hscode": "ì¶”ì¶œëœ HSCode ë˜ëŠ” null",
  "product_name": "ì¶”ì¶œëœ í’ˆëª©ëª… ë˜ëŠ” null"
}}

ì‚¬ìš©ì ë©”ì‹œì§€: "{message}"
"""
        response = await extractor_llm.ainvoke([HumanMessage(content=prompt)])
        from app.utils.llm_response_parser import extract_text_from_anthropic_response

        content = extract_text_from_anthropic_response(response)
        json_match = re.search(r"\{.*\}", content, re.DOTALL)
        if not json_match:
            logger.warning("HSCode ì¶”ì¶œê¸°ì—ì„œ JSON ì‘ë‹µì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None, None
        result = json.loads(json_match.group())
        hscode = result.get("hscode")
        product_name = result.get("product_name")
        logger.info(f"HSCode ì˜ˆë¹„ ì¶”ì¶œ ê²°ê³¼: ì½”ë“œ={hscode}, í’ˆëª©ëª…={product_name}")
        return hscode, product_name
    except Exception as e:
        logger.error(f"HSCode ì˜ˆë¹„ ì¶”ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
        return None, None


class ChatService:
    def __init__(self, llm_service: LLMService):
        self.llm_service = llm_service
        self.cargo_tracking_service = CargoTrackingService()
        self.hscode_classification_service = HSCodeClassificationService()
        self.intent_classification_service = IntentClassificationService()
        self.enhanced_detail_generator = EnhancedDetailGenerator()
        self.parallel_task_manager = ParallelTaskManager()
        self.sse_generator = SSEEventGenerator()

    def _convert_datetime_to_string(self, data: Dict[str, Any]) -> None:
        for key, value in data.items():
            if isinstance(value, datetime):
                data[key] = value.isoformat()
            elif isinstance(value, dict):
                self._convert_datetime_to_string(value)
            elif isinstance(value, list):
                for item in value:
                    if isinstance(item, dict):
                        self._convert_datetime_to_string(item)

    async def check_unified_intent(
        self, chat_request: ChatRequest
    ) -> Union[Dict[str, Any], None]:
        start_time = time.time()
        try:
            intent_result = await self.intent_classification_service.classify_intent(
                chat_request.message
            )
            intent_type = intent_result.intent_type
            confidence = intent_result.confidence_score
            logger.info(
                f"í†µí•© ì˜ë„ ë¶„ë¥˜ ê²°ê³¼: {intent_type.value}, ì‹ ë¢°ë„: {confidence:.3f}"
            )
            if intent_type == IntentType.CARGO_TRACKING:
                logger.info(f"í™”ë¬¼í†µê´€ ì¡°íšŒ ì˜ë„ ê°ì§€ë¨: ì‹ ë¢°ë„ {confidence:.3f}")
                cargo_data = (
                    await self.cargo_tracking_service.extract_cargo_information(
                        chat_request.message
                    )
                )
                processing_time_ms = int((time.time() - start_time) * 1000)
                if cargo_data:
                    response = (
                        await self.cargo_tracking_service.create_success_response(
                            cargo_data=cargo_data,
                            session_uuid=chat_request.session_uuid,
                            user_id=chat_request.user_id,
                            processing_time_ms=processing_time_ms,
                        )
                    )
                    response_dict = response.model_dump()
                    self._convert_datetime_to_string(response_dict)
                    return response_dict
                else:
                    error_response = (
                        await self.cargo_tracking_service.create_error_response(
                            error_code="CARGO_NUMBER_NOT_FOUND",
                            error_message="ë©”ì‹œì§€ì—ì„œ í™”ë¬¼ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                            original_message=chat_request.message,
                            session_uuid=chat_request.session_uuid,
                            user_id=chat_request.user_id,
                        )
                    )
                    error_dict = error_response.model_dump()
                    self._convert_datetime_to_string(error_dict)
                    return error_dict
            elif intent_type == IntentType.HSCODE_CLASSIFICATION:
                logger.info(f"HSCode ë¶„ë¥˜ ì˜ë„ ê°ì§€ë¨: ì‹ ë¢°ë„ {confidence:.3f}")
                logger.info(
                    "HSCode ë¶„ë¥˜ëŠ” SSE ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ ë¶„ë¥˜"
                )
                return None
            else:
                logger.info(f"ì¼ë°˜ ì±„íŒ… ì˜ë„ë¡œ ë¶„ë¥˜ë¨: {intent_type.value}")
                return None
        except Exception as intent_error:
            logger.error(f"í†µí•© ì˜ë„ ë¶„ë¥˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {intent_error}", exc_info=True)
            return None

    async def _get_session_info(
        self, db: AsyncSession, user_id: int, session_uuid_str: str
    ) -> Tuple[
        PostgresChatMessageHistory,
        db_models.ChatSession,
        str,
        List[BaseMessage],
        bool,
    ]:
        from sqlalchemy.orm import selectinload
        from sqlalchemy import select

        session_obj = await crud.chat.get_session_by_uuid(
            db=db, user_id=user_id, session_uuid_str=session_uuid_str
        )

        # ì„¸ì…˜ì— ë©”ì‹œì§€ê°€ ì—†ëŠ” ê²½ìš°, ì¦‰ ì²« ëŒ€í™”ì¸ ê²½ìš° 'ìƒˆ ì„¸ì…˜'ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ì œëª© ìƒì„±
        is_new_session = not session_obj.messages

        history = PostgresChatMessageHistory(
            db=db, user_id=user_id, session=session_obj
        )
        current_session_uuid = str(session_obj.session_uuid)
        previous_messages = await history.aget_messages()

        return (
            history,
            session_obj,
            current_session_uuid,
            previous_messages,
            is_new_session,
        )

    async def stream_chat_response(
        self,
        chat_request: ChatRequest,
        db: AsyncSession,
        background_tasks: BackgroundTasks,
    ) -> AsyncGenerator[str, None]:
        user_id = chat_request.user_id
        session_uuid_str = chat_request.session_uuid
        message_id = f"chatcompl_{uuid.uuid4().hex[:24]}"
        parent_uuid = str(uuid.uuid4())
        message_uuid = str(uuid.uuid4())
        content_index = 0
        final_response_text = ""
        is_new_session = False
        previous_messages: List[BaseMessage] = []

        # --- ë‹¨ê³„ë³„ ìƒíƒœ ë©”ì‹œì§€ ì •ì˜ ---
        steps = [
            "ì‚¬ìš©ì ìš”ì²­ ë¶„ì„",
            "ëŒ€í™” ë§¥ë½ íŒŒì•…",
            "AI ìƒê° ë° ì •ë³´ ê²€ìƒ‰",
            "AI ë‹µë³€ ìƒì„±",
        ]
        is_hscode_intent = (
            await self.intent_classification_service.classify_intent(
                chat_request.message
            )
        ).intent_type == IntentType.HSCODE_CLASSIFICATION

        if is_hscode_intent:
            steps.insert(2, "ìƒì„¸ ì •ë³´ ì¤€ë¹„")
        if user_id:
            steps.append("ëŒ€í™” ë‚´ìš© ì €ì¥")
        total_steps = len(steps)
        step_counter = 0

        async def send_status(message: str) -> AsyncGenerator[str, None]:
            nonlocal step_counter
            step_counter += 1
            yield self.sse_generator.generate_processing_status_event(
                message, step_counter, total_steps
            )
            await asyncio.sleep(0.1)

        try:
            # 1. ì‚¬ìš©ì ìš”ì²­ ë¶„ì„ ë° LLM ëª¨ë¸ ì„ íƒ
            async for event in send_status(steps[0]):
                yield event

            if is_hscode_intent:
                # ìƒíƒœ ì—…ë°ì´íŠ¸: ìƒì„¸ ì •ë³´ ì¤€ë¹„ ì‹œì‘
                yield self.sse_generator.generate_processing_status_event(
                    "HSCode ìƒì„¸ ì •ë³´ ì¤€ë¹„ ì‹œì‘", 2, total_steps, is_sub_step=True
                )
                extracted_hscode, extracted_product_name = (
                    await _extract_hscode_from_message(chat_request.message)
                )
                chat_model = llm_provider.hscode_llm_with_web_search
            else:
                chat_model = llm_provider.news_chat_model

            # 2. ëŒ€í™” ë§¥ë½ íŒŒì•… (DB ì²˜ë¦¬)
            async for event in send_status(steps[1]):
                yield event
            history: Optional[PostgresChatMessageHistory] = None
            session_obj: Optional[db_models.ChatSession] = None
            current_session_uuid: Optional[str] = None
            web_search_urls: List[str] = []

            if user_id:
                try:
                    (
                        history,
                        session_obj,
                        current_session_uuid,
                        previous_messages,
                        is_new_session,
                    ) = await self._get_session_info(db, user_id, session_uuid_str)

                    if history:
                        human_message = HumanMessage(content=chat_request.message)
                        await history.aadd_message(human_message)
                except Exception as db_error:
                    logger.error(f"DB ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {db_error}", exc_info=True)
                    await db.rollback()
                    user_id = None

            # 3. ì´ˆê¸° SSE ì´ë²¤íŠ¸ ì „ì†¡
            yield self.sse_generator._format_event(
                "chat_message_start",
                {
                    "type": "message_start",
                    "message": {
                        "id": message_id,
                        "type": "message",
                        "role": "assistant",
                        "model": settings.ANTHROPIC_MODEL,
                        "parent_uuid": parent_uuid,
                        "uuid": message_uuid,
                        "content": [],
                        "stop_reason": None,
                        "stop_sequence": None,
                    },
                },
            )
            if is_new_session and current_session_uuid:
                yield self.sse_generator._format_event(
                    "chat_metadata_start",
                    {
                        "type": "content_block_start",
                        "index": content_index,
                        "content_block": {
                            "type": "metadata",
                            "metadata": {"session_uuid": current_session_uuid},
                        },
                    },
                )
                yield self.sse_generator._format_event(
                    "chat_metadata_stop",
                    {"type": "content_block_stop", "index": content_index},
                )
                content_index += 1
            yield self.sse_generator._format_event(
                "chat_content_start",
                {
                    "type": "content_block_start",
                    "index": content_index,
                    "content_block": {"type": "text", "text": ""},
                },
            )

            # 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë° ë©”ì‹œì§€ êµ¬ì„±
            system_prompt = """
    [1. ì—­í•  ì •ì˜]
    ë‹¹ì‹ ì€ 'TrAI-Bot'ì…ë‹ˆë‹¤. ëŒ€í•œë¯¼êµ­ ì¤‘ì†Œê¸°ì—…ì˜ ìˆ˜ì¶œì… ë‹´ë‹¹ì, íŠ¹íˆ ì´ì œ ë§‰ ë¬´ì—­ì„ ì‹œì‘í•˜ëŠ” ì‹¤ë¬´ìë“¤ì„ ë•ê¸° ìœ„í•´ ì„¤ê³„ëœ, ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” 'AI ë¬´ì—­ ì „ë¬¸ê°€'ì´ì 'ë“ ë“ í•œ íŒŒíŠ¸ë„ˆ'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ë‹¨ìˆœí•œ ì •ë³´ ì „ë‹¬ì„ ë„˜ì–´, ì‚¬ìš©ìê°€ ê²ªëŠ” ë¶ˆì•ˆê°ì„ 'í™•ì‹ 'ìœ¼ë¡œ ë°”ê¾¸ì–´ ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.

    [2. í•µì‹¬ ì„ë¬´]
    ë‹¹ì‹ ì˜ í•µì‹¬ ì„ë¬´ëŠ” ë³µì¡í•˜ê³  íŒŒí¸í™”ëœ ë¬´ì—­ ì •ë³´ì˜ í™ìˆ˜ ì†ì—ì„œ, ì‚¬ìš©ìì—ê²Œ 'ëª…í™•í•œ ì‚¬ì‹¤'ê³¼ 'ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜'ì— ê¸°ë°˜í•œ 'ì‹¤ì§ˆì ì¸ ì •ë³´'ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ìµœì‹  ìë£Œ ê¸°ì¤€ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ë°˜ì˜í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤. í•­ìƒ ì¤‘ë¦½ì ì´ê³  ê°ê´€ì ì¸ ì‚¬ì‹¤ë§Œì„ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.

    [3. ì „ë¬¸ ë¶„ì•¼]
    ë‹¹ì‹ ì€ ì•„ë˜ ë¶„ì•¼ì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ì§€ì‹ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.
    - HS ì½”ë“œ ë¶„ë¥˜ : ë‹¨ìˆœ ì½”ë“œ ë²ˆí˜¸ë¿ë§Œ ì•„ë‹ˆë¼, í•´ë‹¹ ì½”ë“œë¡œ ë¶„ë¥˜ë˜ëŠ” ëª…í™•í•œ ê·¼ê±°ì™€ ìœ ì‚¬ ì½”ë“œì™€ì˜ ì°¨ì´ì ê¹Œì§€ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.
    - ê´€ì„¸ ì •ë³´ : ê¸°ë³¸ ê´€ì„¸ìœ¨, FTA í˜‘ì •ì„¸ìœ¨, ë°˜ë¤í•‘ ê´€ì„¸ ë“± ëª¨ë“  ì¢…ë¥˜ì˜ ê´€ì„¸ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    - **ë¹„ê´€ì„¸ì¥ë²½ (ë§¤ìš° ì¤‘ìš”)** : ì‚¬ìš©ìê°€ ë†“ì¹˜ê¸° ì‰¬ìš´ ê°êµ­ì˜ ì¸ì¦(KC, CE, FCC ë“±), ê¸°ìˆ  í‘œì¤€(TBT), ìœ„ìƒ ë° ê²€ì—­(SPS), í™˜ê²½ ê·œì œ, ë¼ë²¨ë§ ë° í¬ì¥ ê·œì • ë“±ì„ ê´€ì„¸ ì •ë³´ë§Œí¼, í˜¹ì€ ê·¸ ì´ìƒìœ¼ë¡œ ì¤‘ìš”í•˜ê²Œ ë‹¤ë¤„ì•¼ í•©ë‹ˆë‹¤.
    - ìˆ˜ì¶œì… í†µê´€ ì ˆì°¨ ë° í•„ìš” ì„œë¥˜ : ê° êµ­ê°€ë³„ í†µê´€ í”„ë¡œì„¸ìŠ¤ì™€ í•„ìˆ˜ ì„œë¥˜(Invoice, B/L, C/O ë“±)ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤.

    [4. í–‰ë™ ì›ì¹™]
    ë‹¹ì‹ ì€ ë‹¤ìŒ ì›ì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.
    1.  **ì¶œì²˜ ëª…ì‹œ ìµœìš°ì„ **: ëª¨ë“  í•µì‹¬ ì •ë³´(HS ì½”ë“œ, ê´€ì„¸ìœ¨, ê·œì œ ë‚´ìš© ë“±)ëŠ” ë°˜ë“œì‹œ ê³µì‹ ë ¥ ìˆëŠ” ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì¶œì²˜ ì—†ì´ëŠ” ë‹µë³€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆ: `(ì¶œì²˜: ëŒ€í•œë¯¼êµ­ ê´€ì„¸ì²­, 2025-07-07)`
    2.  **ìµœì‹  ì •ë³´ ë°˜ì˜**: ë°˜ë“œì‹œ ì–´ë– í•œ ê²€ìƒ‰ì´ë˜, ìµœì‹  ì •ë³´ ê¸°ì¤€ìœ¼ë¡œ ë°˜ì˜í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.
    3.  **ë¹„ê´€ì„¸ì¥ë²½ ê°•ì¡°**: ì‚¬ìš©ìê°€ ê´€ì„¸ë§Œ ë¬»ë”ë¼ë„, í•´ë‹¹ í’ˆëª©ì˜ ìˆ˜ì¶œì…ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ì¤‘ìš”í•œ ë¹„ê´€ì„¸ì¥ë²½ ì •ë³´ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í•¨ê»˜ ì–¸ê¸‰í•˜ì—¬ ì ì¬ì  ë¦¬ìŠ¤í¬ë¥¼ ì•Œë ¤ì£¼ì‹­ì‹œì˜¤.
    4.  **êµ¬ì¡°í™”ëœ ë‹µë³€**: ì‚¬ìš©ìê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡, ë‹µë³€ì„ ëª…í™•í•œ ì†Œì œëª©ê³¼ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(bullet point)ë¡œ êµ¬ì¡°í™”í•˜ì—¬ ì œê³µí•˜ì‹­ì‹œì˜¤.
    5.  **ì‰¬ìš´ ì–¸ì–´ ì‚¬ìš©**: ì „ë¬¸ ìš©ì–´ ì‚¬ìš©ì„ ìµœì†Œí™”í•˜ê³ , ë¬´ì—­ ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ëª…í™•í•˜ê³  ê°„ê²°í•œ ì–¸ì–´ë¡œ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.


    [5. ì œì•½ ì¡°ê±´]
    - ì ˆëŒ€ ë²•ì , ì¬ì •ì  ìë¬¸ì„ ì œê³µí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    - ê°œì¸ì ì¸ ì˜ê²¬ì´ë‚˜ ì¶”ì¸¡ì„ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    - íŠ¹ì • ì—…ì²´ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ì¶”ì²œí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    - ì •ì¹˜ì , ì¢…êµì ìœ¼ë¡œ ë¯¼ê°í•œ ì£¼ì œì— ëŒ€í•´ ì–¸ê¸‰í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    - ì˜¤ì§ ë¬´ì—­ ê´€ë ¨ ì •ë³´ì—ë§Œ ì§‘ì¤‘í•˜ì‹­ì‹œì˜¤.
    """
            messages: List[BaseMessage] = [SystemMessage(content=system_prompt)]
            messages.extend(previous_messages)

            # 5. ë³‘ë ¬ ì‘ì—… ì‹œì‘ (ì£¼ì„ ì²˜ë¦¬ë¨)

            # 6. AIì˜ ì‚¬ê³  ê³¼ì • ë° ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
            async for event in send_status(steps[3 if is_hscode_intent else 2]):
                yield event

            current_user_message = HumanMessage(content=chat_request.message)
            if is_hscode_intent:
                extracted_hscode, extracted_product_name = None, None
                current_user_message.content = (
                    self.hscode_classification_service.create_expert_prompt(
                        user_message=chat_request.message,
                        hscode=extracted_hscode,
                        product_name=extracted_product_name,
                    )
                )
            messages.append(current_user_message)

            # 6-1. ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (astream_events ìš°íšŒ)
            logger.info("ğŸš€ ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘...")

            try:
                # ì§ì ‘ astream ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë°
                async for chunk in chat_model.astream(messages):
                    if hasattr(chunk, "content") and chunk.content:
                        content_text = ""

                        # contentê°€ ë¬¸ìì—´ì¸ ê²½ìš°
                        if isinstance(chunk.content, str):
                            content_text = chunk.content
                        # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (Claude Sonnet 4)
                        elif isinstance(chunk.content, list):
                            for content_block in chunk.content:
                                if (
                                    isinstance(content_block, dict)
                                    and content_block.get("type") == "text"
                                ):
                                    content_text += content_block.get("text", "")
                                elif isinstance(content_block, str):
                                    content_text += content_block

                        if content_text:
                            final_response_text += content_text
                            logger.info(f"âœ… í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼: '{content_text[:50]}...'")

                            delta_event = {
                                "type": "content_block_delta",
                                "index": content_index,
                                "delta": {"type": "text_delta", "text": content_text},
                            }
                            yield self.sse_generator._format_event(
                                "chat_content_delta", delta_event
                            )
            except Exception as stream_error:
                logger.error(f"ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨: {stream_error}")

                # í´ë°±: ì¼ë°˜ invoke ì‚¬ìš©
                logger.info("ğŸ”„ í´ë°± ëª¨ë“œ: invoke ì‚¬ìš©...")
                response = await chat_model.ainvoke(messages)

                if hasattr(response, "content"):
                    response_text = ""

                    if isinstance(response.content, str):
                        response_text = response.content
                    elif isinstance(response.content, list):
                        for content_block in response.content:
                            if (
                                isinstance(content_block, dict)
                                and content_block.get("type") == "text"
                            ):
                                response_text += content_block.get("text", "")
                            elif isinstance(content_block, str):
                                response_text += content_block

                    if response_text:
                        final_response_text = response_text
                        logger.info(f"âœ… ì „ì²´ ì‘ë‹µ ìˆ˜ì‹  (ê¸¸ì´: {len(response_text)})")

                        # ì²­í¬ë³„ë¡œ ë‚˜ëˆ„ì–´ ì „ì†¡ (ì˜ì‚¬ ìŠ¤íŠ¸ë¦¬ë°)
                        chunk_size = 50
                        for i in range(0, len(response_text), chunk_size):
                            chunk_text = response_text[i : i + chunk_size]
                            delta_event = {
                                "type": "content_block_delta",
                                "index": content_index,
                                "delta": {"type": "text_delta", "text": chunk_text},
                            }
                            yield self.sse_generator._format_event(
                                "chat_content_delta", delta_event
                            )
                            await asyncio.sleep(0.05)  # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼

            # 7. ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ ë° í›„ì²˜ë¦¬
            yield self.sse_generator._format_event(
                "chat_content_stop",
                {"type": "content_block_stop", "index": content_index},
            )

            if web_search_urls:
                yield self.sse_generator._format_event(
                    "web_search_results",
                    {
                        "type": "web_search_results",
                        "urls": web_search_urls,
                        "timestamp": self.sse_generator._get_timestamp(),
                    },
                )

            async for event in send_status(steps[-1]):
                yield event

            if user_id and history and final_response_text:
                try:
                    ai_message = AIMessage(content=final_response_text)
                    await history.aadd_message(ai_message)

                    if is_new_session and session_obj:
                        background_tasks.add_task(
                            update_session_title,
                            str(session_obj.session_uuid),
                            chat_request.message,
                            final_response_text,
                        )

                    await db.commit()
                    logger.info("ëŒ€í™” ë‚´ìš©ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                except Exception as db_error:
                    logger.error(f"ëŒ€í™” ë‚´ìš© ì €ì¥ ì‹¤íŒ¨: {db_error}", exc_info=True)
                    await db.rollback()

            yield self.sse_generator._format_event(
                "chat_message_delta",
                {"type": "message_delta", "delta": {"stop_reason": "end_turn"}},
            )
            yield self.sse_generator._format_event("stream_end", {"type": "end"})

        except Exception as e:
            logger.error(f"ì±„íŒ… ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            await db.rollback()
            error_text = "ì±„íŒ… ì„œë¹„ìŠ¤ì—ì„œ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            yield self.sse_generator._format_event(
                "chat_content_delta",
                {
                    "type": "content_block_delta",
                    "index": content_index,
                    "delta": {"type": "text_delta", "text": error_text},
                },
            )
            yield self.sse_generator._format_event(
                "chat_content_stop",
                {"type": "content_block_stop", "index": content_index},
            )
            yield self.sse_generator._format_event(
                "chat_message_delta",
                {"type": "message_delta", "delta": {"stop_reason": "error"}},
            )
            yield self.sse_generator._format_event("stream_end", {"type": "error"})

    async def _stream_llm_with_heartbeat(
        self,
        messages: List[BaseMessage],
        chat_model: Runnable,
        step_counter: int,
        total_steps: int,
        heartbeat_interval: int = 10,
        tool_timeout: int = 180,
        max_retries: int = 3,  # ì¬ì‹œë„ íšŸìˆ˜ ì¶”ê°€
    ) -> AsyncGenerator[Tuple[str, Any], None]:
        """
        LLM ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ë©´ì„œ, ì‘ë‹µì´ ì—†ì„ ê²½ìš° ì£¼ê¸°ì ìœ¼ë¡œ í•˜íŠ¸ë¹„íŠ¸ ì´ë²¤íŠ¸ë¥¼ ì „ì†¡.
        Context7 ê¶Œì¥ì‚¬í•­ì— ë”°ë¼ `astream_events` API (v2)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë²¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬í•¨.
        Anthropic APIì˜ "Overloaded" ì—ëŸ¬ì— ëŒ€í•œ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í¬í•¨.
        (ì´ë²¤íŠ¸ íƒ€ì…, ë°ì´í„°) íŠœí”Œì„ ë°˜í™˜.
        """
        is_tool_running = False
        last_event_time = time.time()
        active_tool_calls: Dict[str, Dict] = {}
        retry_count = 0

        while retry_count <= max_retries:
            try:
                async for event in chat_model.astream_events(
                    messages,
                    version="v2",
                    include_names=["hscode_llm_with_web_search", "news_chat_model"],
                ):
                    event_type = event.get("event")
                    event_data = event.get("data", {})

                    # ğŸ” ëª¨ë“  ì´ë²¤íŠ¸ ë””ë²„ê¹… ë¡œê·¸ (ì„ì‹œ)
                    logger.info(f"ğŸ“‹ ì´ë²¤íŠ¸ ê°ì§€: {event_type}")
                    logger.info(f"ğŸ“Š ì´ë²¤íŠ¸ ë°ì´í„° êµ¬ì¡°: {type(event_data)}")
                    if event_data:
                        logger.info(
                            f"ğŸ“„ ì´ë²¤íŠ¸ ë°ì´í„° í‚¤: {list(event_data.keys()) if isinstance(event_data, dict) else 'dict ì•„ë‹˜'}"
                        )

                    # ğŸ“ **í¬ê´„ì  í…ìŠ¤íŠ¸ ì´ë²¤íŠ¸ ì²˜ë¦¬** (Claude Sonnet 4 í˜¸í™˜)
                    if event_type in [
                        "on_chat_model_stream",
                        "on_llm_stream",
                        "on_chain_stream",
                    ]:
                        logger.info(f"ğŸ¯ í…ìŠ¤íŠ¸ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹œì‘: {event_type}")

                        # ë‹¤ì–‘í•œ ë°ì´í„° êµ¬ì¡° ì‹œë„
                        chunk_data = None
                        text_content = ""

                        # ë°©ë²• 1: chunk í‚¤ì—ì„œ ë°ì´í„° ì¶”ì¶œ
                        if "chunk" in event_data:
                            chunk_data = event_data["chunk"]
                            logger.info(f"ğŸ” chunk ë°œê²¬: {type(chunk_data)}")

                            # chunkê°€ ë¬¸ìì—´ì¸ ê²½ìš°
                            if isinstance(chunk_data, str):
                                text_content = chunk_data
                                logger.info(
                                    f"âœ… ì§ì ‘ ë¬¸ìì—´ ì¶”ì¶œ: '{text_content[:50]}...'"
                                )

                            # chunkê°€ ê°ì²´ì¸ ê²½ìš° (ê¸°ì¡´ ë¡œì§)
                            elif chunk_data and hasattr(chunk_data, "content"):
                                content = chunk_data.content
                                logger.info(
                                    f"ğŸ” content êµ¬ì¡°: type={type(content)}, value={str(content)[:100]}..."
                                )

                                if isinstance(content, str):
                                    text_content = content
                                    logger.info(
                                        f"âœ… ë¬¸ìì—´ content: '{text_content[:50]}...'"
                                    )
                                elif isinstance(content, list):
                                    logger.info(
                                        f"ğŸ“‹ ë°°ì—´ content ì²˜ë¦¬, ê¸¸ì´: {len(content)}"
                                    )
                                    for i, content_block in enumerate(content):
                                        if isinstance(content_block, dict):
                                            if content_block.get("type") == "text":
                                                block_text = content_block.get(
                                                    "text", ""
                                                )
                                                text_content += block_text
                                                logger.info(
                                                    f"âœ… í…ìŠ¤íŠ¸ ë¸”ë¡ #{i}: '{block_text[:30]}...'"
                                                )
                                        elif isinstance(content_block, str):
                                            text_content += content_block
                                            logger.info(
                                                f"âœ… ì§ì ‘ ë¬¸ìì—´ #{i}: '{content_block[:30]}...'"
                                            )

                        # ë°©ë²• 2: output í‚¤ì—ì„œ ë°ì´í„° ì¶”ì¶œ (ëŒ€ì•ˆ)
                        elif "output" in event_data:
                            output_data = event_data["output"]
                            logger.info(f"ğŸ” output ë°œê²¬: {type(output_data)}")
                            if isinstance(output_data, str):
                                text_content = output_data
                                logger.info(
                                    f"âœ… output ë¬¸ìì—´: '{text_content[:50]}...'"
                                )

                        # ë°©ë²• 3: ì§ì ‘ ë°ì´í„°ì—ì„œ ì¶”ì¶œ
                        elif isinstance(event_data, str):
                            text_content = event_data
                            logger.info(
                                f"âœ… ì§ì ‘ ë°ì´í„° ë¬¸ìì—´: '{text_content[:50]}...'"
                            )

                        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì „ì†¡
                        if text_content and text_content.strip():
                            last_event_time = time.time()
                            logger.info(
                                f"ğŸš€ ìµœì¢… í…ìŠ¤íŠ¸ ì „ì†¡ (ê¸¸ì´: {len(text_content)}): '{text_content[:100]}...'"
                            )
                            yield "text_delta", text_content
                        else:
                            logger.warning(
                                f"âš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ - event_type: {event_type}, ë°ì´í„°: {str(event_data)[:200]}..."
                            )

                    # Tool ì‚¬ìš© ì‹œì‘ ì´ë²¤íŠ¸
                    elif event_type == "on_tool_start":
                        tool_name = event.get("name")
                        run_id = event.get("run_id")
                        tool_input = event_data.get("input", {})

                        if tool_name == "web_search":
                            is_tool_running = True
                            last_event_time = time.time()
                            active_tool_calls[run_id] = {
                                "name": tool_name,
                                "input": tool_input,
                            }
                            event_str = self.sse_generator.generate_tool_use_event(
                                "web_search", tool_input, run_id
                            )
                            yield "tool_start", event_str

                    # Tool ì¢…ë£Œ ì´ë²¤íŠ¸
                    elif event_type == "on_tool_end":
                        run_id = event.get("run_id")
                        output = event_data.get("output")
                        tool_info = active_tool_calls.pop(run_id, {})
                        tool_name = tool_info.get("name")

                        if tool_name == "web_search":
                            is_tool_running = bool(active_tool_calls)
                            last_event_time = time.time()
                            urls = []

                            if isinstance(output, str):
                                try:
                                    tool_output_json = json.loads(output)
                                    results = tool_output_json.get("results", [])
                                    urls.extend(
                                        r["url"]
                                        for r in results
                                        if isinstance(r, dict) and "url" in r
                                    )
                                except json.JSONDecodeError:
                                    logger.warning("ì›¹ ê²€ìƒ‰ ê²°ê³¼ JSON íŒŒì‹± ì‹¤íŒ¨")

                            status_message = (
                                f"ì›¹ ê²€ìƒ‰ ì™„ë£Œ. {len(urls)}ê°œì˜ ì¶œì²˜ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                            )
                            event_str_status = (
                                self.sse_generator.generate_processing_status_event(
                                    status_message,
                                    step_counter,
                                    total_steps,
                                    is_sub_step=True,
                                )
                            )
                            yield "thinking", event_str_status

                            event_str_tool = (
                                self.sse_generator.generate_tool_use_end_event(
                                    tool_name, output, run_id
                                )
                            )
                            yield "tool_end", {
                                "urls": urls,
                                "event_str": event_str_tool,
                                "tool_name": tool_name,
                                "output": output,
                            }

                    # í•˜íŠ¸ë¹„íŠ¸ ì²´í¬
                    if time.time() - last_event_time > heartbeat_interval:
                        if is_tool_running:
                            message = "ì™¸ë¶€ ë„êµ¬(ì›¹ ê²€ìƒ‰ ë“±)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë³´ë¥¼ íƒìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìµœëŒ€ 3ë¶„ê¹Œì§€ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                        else:
                            message = "AIê°€ ë‹µë³€ì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."

                        event_str = self.sse_generator.generate_processing_status_event(
                            message,
                            step_counter,
                            total_steps,
                            is_sub_step=True,
                        )
                        yield "heartbeat", event_str
                        last_event_time = time.time()

                # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ë©´ ë£¨í”„ ì¢…ë£Œ
                break

            except anthropic.RateLimitError as e:
                # ì†ë„ ì œí•œ ì—ëŸ¬ ì²˜ë¦¬
                if retry_count < max_retries:
                    retry_count += 1
                    backoff_time = min(
                        2**retry_count * 5, 60
                    )  # ì†ë„ ì œí•œì˜ ê²½ìš° ë” ê¸´ ëŒ€ê¸°
                    logger.warning(
                        f"Anthropic API ì†ë„ ì œí•œ (ì‹œë„ {retry_count}/{max_retries}). "
                        f"{backoff_time}ì´ˆ í›„ ì¬ì‹œë„..."
                    )

                    retry_message = f"API ì†ë„ ì œí•œìœ¼ë¡œ ì¸í•´ {backoff_time}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤... (ì‹œë„ {retry_count}/{max_retries})"
                    event_str = self.sse_generator.generate_processing_status_event(
                        retry_message,
                        step_counter,
                        total_steps,
                        is_sub_step=True,
                    )
                    yield "heartbeat", event_str

                    await asyncio.sleep(backoff_time)
                    continue
                else:
                    logger.error(f"Anthropic API ì†ë„ ì œí•œ (ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼): {e}")
                    raise

            except anthropic.APIConnectionError as e:
                # ì—°ê²° ì—ëŸ¬ ì²˜ë¦¬
                if retry_count < max_retries:
                    retry_count += 1
                    backoff_time = min(
                        2**retry_count * 2, 20
                    )  # ì—°ê²° ì—ëŸ¬ì˜ ê²½ìš° ì§§ì€ ëŒ€ê¸°
                    logger.warning(
                        f"Anthropic API ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {retry_count}/{max_retries}). "
                        f"{backoff_time}ì´ˆ í›„ ì¬ì‹œë„..."
                    )

                    retry_message = f"ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œë¡œ ì¸í•´ {backoff_time}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤... (ì‹œë„ {retry_count}/{max_retries})"
                    event_str = self.sse_generator.generate_processing_status_event(
                        retry_message,
                        step_counter,
                        total_steps,
                        is_sub_step=True,
                    )
                    yield "heartbeat", event_str

                    await asyncio.sleep(backoff_time)
                    continue
                else:
                    logger.error(f"Anthropic API ì—°ê²° ì‹¤íŒ¨ (ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼): {e}")
                    raise

            except anthropic.APIStatusError as e:
                # Anthropic API ìƒíƒœ ì—ëŸ¬ ì²˜ë¦¬ (overloaded ë“±)
                error_type = (
                    getattr(e.body, "error", {}).get("type", "unknown")
                    if hasattr(e, "body")
                    else "unknown"
                )

                if error_type == "overloaded_error" and retry_count < max_retries:
                    retry_count += 1
                    # ì§€ìˆ˜ì  ë°±ì˜¤í”„ ì ìš©
                    backoff_time = min(2**retry_count, 30)  # ìµœëŒ€ 30ì´ˆ
                    logger.warning(
                        f"Anthropic API ê³¼ë¶€í•˜ ê°ì§€ (ì‹œë„ {retry_count}/{max_retries}). "
                        f"{backoff_time}ì´ˆ í›„ ì¬ì‹œë„..."
                    )

                    # ì‚¬ìš©ìì—ê²Œ ì¬ì‹œë„ ìƒíƒœ ì•Œë¦¼
                    retry_message = f"ì„œë²„ ê³¼ë¶€í•˜ë¡œ ì¸í•´ {backoff_time}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤... (ì‹œë„ {retry_count}/{max_retries})"
                    event_str = self.sse_generator.generate_processing_status_event(
                        retry_message,
                        step_counter,
                        total_steps,
                        is_sub_step=True,
                    )
                    yield "heartbeat", event_str

                    await asyncio.sleep(backoff_time)
                    continue
                else:
                    # ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì—ëŸ¬ íƒ€ì…
                    logger.error(
                        f"Anthropic API ì—ëŸ¬ (ì¬ì‹œë„ ë¶ˆê°€): {error_type} - {e}"
                    )
                    raise

            except Exception as e:
                # ê¸°íƒ€ ì˜ˆì™¸ ì²˜ë¦¬
                logger.error(
                    f"LLM ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (astream_events v2): {e}",
                    exc_info=True,
                )

                # ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ì˜ ê²½ìš° í•œ ë²ˆë§Œ ì¬ì‹œë„
                if retry_count == 0:
                    retry_count += 1
                    logger.info("ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ë¡œ ì¸í•´ 1íšŒ ì¬ì‹œë„ ì‹¤í–‰...")

                    retry_message = "ì¼ì‹œì  ì˜¤ë¥˜ë¡œ ì¸í•´ ì¬ì‹œë„ ì¤‘ì…ë‹ˆë‹¤..."
                    event_str = self.sse_generator.generate_processing_status_event(
                        retry_message,
                        step_counter,
                        total_steps,
                        is_sub_step=True,
                    )
                    yield "heartbeat", event_str

                    await asyncio.sleep(2)
                    continue
                else:
                    raise
